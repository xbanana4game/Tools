import requestsfrom bs4 import BeautifulSoupimport reimport osimport datetimeimport timeimport configparserconfig = configparser.ConfigParser()config.read(os.getenv('CONFIG_DIR')+'\\webscraping.ini', encoding='utf-8')SITE_NAME = config.get("site", "SITE_NAME")URL_BASE = config.get("site", "URL_BASE")EPISODE_SEARCH = config.get("site", "EPISODE_SEARCH")MAX_PAGE_NUMBER = input('MAX_PAGE_NUMBER: ')if MAX_PAGE_NUMBER == '':    MAX_PAGE_NUMBER = int(config.get("site", "MAX_PAGE_NUMBER"))MAX_PAGE_NUMBER = int(MAX_PAGE_NUMBER)print(MAX_PAGE_NUMBER)    today=datetime.datetime.now()fc = open(os.getenv('USERPROFILE')+'\\Downloads\\'+SITE_NAME+today.strftime("_%Y%m%d%H%M")+'.csv', 'w', encoding='utf-8-sig')fc.write('page,genre,title,episode,url\n')for i in range(1,MAX_PAGE_NUMBER+1):    url = URL_BASE.format(number=i)    print(url)        response = requests.get(url)    # print(response.text)    soup = BeautifulSoup(response.text, "html.parser")    elems = soup.find_all("h2")    for elem in elems:        try:            #print(elem.contents[0])            #print(elem.contents[0].attrs['href'])            #print('--------------------------------------------------------------------------------------')            elem_url=elem.contents[0].attrs['href']            title_raw=elem.contents[0].text            #pattern = re.compile(title_raw, re.IGNORECASE)            genre_search = re.search('^\[(.*?)\]', title_raw)            if genre_search is None:                genre = ''            else:                genre = genre_search.group(1)            episode_search = re.search(EPISODE_SEARCH, title_raw)            try:                if episode_search is None:                    episode = ''                elif episode_search.group(1) is not None:                    episode = '#{:02d}'.format(int(episode_search.group(1)))                elif episode_search.group(2) is not None:                    episode = '#{:02d}'.format(int(episode_search.group(2)))                elif episode_search.group(3) is not None:                    episode = '#{:02d}'.format(int(episode_search.group(3)))                else:                    episode = episode_search.group(0)            except ValueError:                episode = episode_search.group(0)                            title_short = re.sub('raw.*', '', title_raw, flags=re.IGNORECASE)            title_short = re.sub(EPISODE_SEARCH, '', title_short, flags=re.IGNORECASE)            title_short = re.sub('\[.*?\]','', title_short)            title_short = re.sub(' +$','', title_short)            title_short = re.sub('^ +','', title_short)            print(title_raw)                        fc.write('{page},{genre},{title_short},{episode},{url}\n'.format(page=i,genre=genre,title_short=title_short,episode=episode,url=elem_url))            #print('{title:.10},{url:.10}\n'.format(title=title_raw,url=elem.contents[0].attrs['href']))        except AttributeError as e:            print(e)        except KeyError as e:            print(e)    time.sleep(0.3)fc.close()